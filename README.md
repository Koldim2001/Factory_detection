# Проект по детекции
__Проект по созданию системы безопасности на предприятии, реализующей детектирование людей и автоматическую проверку наличия касок по изображениям с видеокамер__

---
Я сделал обучение двух различных нейронных сетей Faster-RCNN с FPN (Region Based Convolutional Neural Network with Feature Pyramid Architecture). Первая сеть реализует детектирование людей по изображениям с видеокамер, а вторая проверяет наличие касок на головах работников предприятия. <br> Для того чтобы получить более качественную детекцию, я использовал технологию transfer learning, инициализировав на старте предобученные веса. После завершения обучения сетей я сохранил состояния моделей, которые показали наименьший суммарный лосс на валидации.
Далее я реализовал оценку качества детектирования, используя самостоятельно написанные функции, которые считали метрики на валидации: 
1. среднее IOU;
2. recall и precision при заданных порогах уверенности (score) и IoU; 
3. значения average precision (AP) для каждого класса;
4. mean average precision (mAP) для модели двухклассовой детекции c различными порогами по IoU.<br>

В процессе обучения моделей я также проводил мониторинг изменения лосс функций на трейне и валидации. Данные результаты сохранил результаты в [tensorboard.dev](https://tensorboard.dev/experiment/rr43qafqQKyKP7CQ5r1RCA/#scalars&_smoothingWeight=0)<br>

## __Содержание репозитория:__
Ключевой файл - отчет в формате jupiter notebook __main.ipynb__, в котором представлено подробное описание реализованного проекта и описаны все шаги по предподготовке, обучению и тестированию моделей с выводами. Все ключевые для данного проекта функции я представил в отдельных _.py_ файлах: 
1. реализация аугментации и визуализация исходных данных - __augment_and_visualize.py__
2. реализация обучения сетей с параллельным тестированием на валидации и трекингом в tensorboard - __training_rcnn.py__
3. визаулизация результатов детекции и загрузка обученных моделей с гугл диска - __predict.py__
4. подсчет всех ключевых метрик для оценки качества детектирования - __metrics.py__

Для того, чтобы была возможность самостоятельно протестировать работоспособность двух обученных моделей детектирования, написал скрипт __detecting.py__, который запрашивает путь к файлу (jpg/png) и визуализирует результаты распознавания. О том, как запустить этот скрипт через терминал и с помошью docker сейчас подробно расскажу:

---

## Как запускать программу:
### С помощью терминала:
(данные команды требуется запускать последовательно)
1. Склонируйте к себе этот репозиторий 
```
git clone https://github.com/Koldim2001/Factory_detection.git
```
2. Gерейдите с помощью команды cd в созданную папку Factory_detection
```
cd Factory_detection
```
3. Загрузите все необходимые библиотеки:
```
pip install -r requirements.txt
```
4. Запустите написанный python скрипт:
```
python detecting.py
```

При запуске программы потребуется ввести путь к изображению, для которого надо провети детекцию.
После завершения детектирования людей откроется отдельное окно с результирующими боксами. При закрытии этого окна
автоматически начнется процедура двухклассовой детекции (наличие/отсутвие касок на голове). По результатам вычислений откроется отдельное окно с задетектированными боксами.<br><br>
_Примеры результатов работы двух разных обученных моделей:_

<div style="text-align:center;">
  <img src="https://drive.google.com/uc?id=1Dtu_bK9w5Hl65A6lETChuu1Ftz2wirUi" alt="Alt person detection" width="380" height="217">
  <img src="https://drive.google.com/uc?id=105RsKrPwpzGLTbyUYjKDsDRP0bd6IUIT" alt="Alt hardhat detection" width="380" height="217">
</div>

