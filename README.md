# Проект по детекции
__Проект по созданию системы безопасности на предприятии, реализующей детектирование людей и автоматическую проверку наличия касок по изображениям с видеокамер__

---
Я сделал обучение двух различных нейронных сетей Faster-RCNN с FPN (Region Based Convolutional Neural Network with Feature Pyramid Architecture). Первая сеть реализует детектирование людей по изображениям с видеокамер, а вторая проверяет наличие касок на головах работников предприятия. <br> Для того чтобы получить более качественную детекцию, я использовал технологию transfer learning, инициализировав на старте предобученные веса. После завершения обучения сетей я сохранил состояния моделей, которые показали наименьший суммарный лосс на валидации.
Далее я реализовал оценку качества детектирования, используя самостоятельно написанные функции, которые вычисляли следующие валидационные метрики: 
1. среднее IOU;
2. recall и precision при заданных порогах уверенности (score) и IoU; 
3. значения average precision (AP) для каждого класса;
4. mean average precision (mAP) для модели двухклассовой детекции c различными порогами по IoU.<br>

В процессе обучения моделей я также проводил мониторинг изменения лосс функций на трейне и валидации. Данные результаты сохранил в [tensorboard.dev](https://tensorboard.dev/experiment/rr43qafqQKyKP7CQ5r1RCA/#scalars&_smoothingWeight=0)<br>

## __Содержание репозитория:__
Ключевой файл - отчет в формате jupiter notebook [__main.ipynb__](https://nbviewer.org/github/Koldim2001/Factory_detection/blob/main/main.ipynb?flush_cache=True/), в котором представлено подробное описание реализованного проекта и описаны все шаги по предобработке данных, а также обучению и тестированию моделей с выводами. Все ключевые для данного проекта функции я представил в отдельных _.py_ файлах: 
1. реализация аугментации и визуализация исходных данных - [__augment_and_visualize.py__](https://github.com/Koldim2001/Factory_detection/blob/main/augment_and_visualize.py)
2. реализация обучения сетей с параллельным тестированием на валидации и трекингом в tensorboard - [__training_rcnn.py__](https://github.com/Koldim2001/Factory_detection/blob/main/training_rcnn.py)
3. визаулизация результатов детекции и загрузка обученных моделей с гугл диска - [__predict.py__](https://github.com/Koldim2001/Factory_detection/blob/main/predict.py)
4. подсчет всех ключевых метрик для оценки качества детектирования - [__metrics.py__](https://github.com/Koldim2001/Factory_detection/blob/main/metrics.py)

Для того, чтобы была возможность самостоятельно протестировать работоспособность двух обученных моделей детектирования, написал скрипт [detecting.py](https://github.com/Koldim2001/Factory_detection/blob/main/detecting.py), который запрашивает путь к файлу (jpg/png) и визуализирует результаты распознавания. О том, как запустить этот скрипт через терминал будет далее подробно рассказано.

_Примеры результатов работы двух разных обученных моделей:_

<div style="text-align:center;">
  <img src="https://drive.google.com/uc?id=1Dtu_bK9w5Hl65A6lETChuu1Ftz2wirUi" alt="Alt person detection" width="380" height="217">
  <img src="https://drive.google.com/uc?id=105RsKrPwpzGLTbyUYjKDsDRP0bd6IUIT" alt="Alt hardhat detection" width="380" height="217">
</div>

---

## Как запускать программу:
Данные команды требуется запускать последовательно в терминале:
1. Склонируйте к себе этот репозиторий 
```
git clone https://github.com/Koldim2001/Factory_detection.git
```
2. Перейдите с помощью команды cd в созданную папку Factory_detection
```
cd Factory_detection
```
3. Загрузите все необходимые библиотеки:
```
pip install -r requirements.txt
```
4. Запустите написанный python скрипт:
```
python detecting.py
```

_При запуске программы потребуется ввести путь к изображению, для которого надо провести детекцию. Учтите, что путь к файлу не должен содержать кириллицу (русские буквы).
После завершения детектирования людей откроется отдельное окно с результирующими боксами. При закрытии этого окна
автоматически начнется процедура двухклассовой детекции (наличие/отсутвие касок на голове). По результатам вычислений откроется новое отдельное окно с задетектированными боксами.<br><br>_

---
### Способ запуска детектирования с помощью telegram бота:<br>
Я реализовал интеграцию модели детектирования людей в чат бот. При отправлении изображения в лс он выдает число обнаруженных объектов и отправляет ответное изображение с предсказанными bounding боксами. <br>
__Инструкция по запуску "локального сервера", реализующего работу бота:__ <br>
Первые 3 этапа идентичны описанным ранее. <br>
4. Запустите написанный python скрипт:
```
python tg_bot.py
```
5. Перейдите в диалог с ботом по [ссылке](https://t.me/KexampleBot) <br>

PS: Данный сервер может быть единовременно запущен лишь на одном компьютере. Так что перед самостоятельным запуском убедитесь, что бот не работает, либо попросите [меня](https://t.me/kolesnikov_dima) его самостоятельно запустить для демонстрации.

